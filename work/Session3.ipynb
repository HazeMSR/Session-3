{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2926c2-bfd3-4334-bafe-13abe5aea02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9f74d4-cda7-45c1-98a0-9ba37f364a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cdb5c6-e13f-4500-a6b8-7bed3a4338dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63829f75-b440-4a5b-b1a6-f8542a3e6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resilient Distributed Dataset. \n",
    "nums = sc.parallelize([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f368c-8209-47ee-93a7-8b12800aef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nums.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b3454-15db-4260-ab08-5b8b5e099637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying some transformation with a lambda function to our set\n",
    "squared = nums.map(lambda x: x*x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29593ecc-87b0-4e2a-9f85-9f6909575a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQLContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99506042-3cac-4f94-9490-dd92a8b71d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But SQLContext it's already deprecated use SparkSession instead\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Session3').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1b4416-aaff-437e-b4a7-954dd12738c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_p = [('John',19),('Smith',29),('Adam',35),('Henry',50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1356b52-6b17-4f14-9c6b-9de5467bbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a parallel RDD collection\n",
    "rdd = sc.parallelize(list_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c70e4-5f2a-44d4-a3f2-d3f0be688c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca6fcf-6569-4393-841a-83b0299fa322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the RDD to tuples\n",
    "ppl = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c66eb-6165-4bb6-b1f0-72be87141f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536059ef-e016-40fd-b52a-75ab9976cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppl = spark.createDataFrame(ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ef76f-c380-4bba-a9ee-11885c6d6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3bb16-4c6e-48c4-8744-c54d0e809011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ppl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53cc9ac-7d8e-4f7f-b224-80302fb35df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"adult_data.csv\"\n",
    "from pyspark import SparkFiles\n",
    "#sc.addFile(file)\n",
    "\n",
    "# Add a file to be downloaded with this Spark job on every node\n",
    "spark.sparkContext.addFile(file)\n",
    "\n",
    "# sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba3249-2f9b-42b0-a92b-41a084c8ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlContext.read.csv\n",
    "\n",
    "# Load your file to your sql context inside spark session\n",
    "df = spark.read.csv(SparkFiles.get(\"adult_data.csv\"), header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55d0ac7-c5d7-4d7c-88e0-2281b96a9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ea5ed-fe50-4496-9dfb-db643620abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fdb232dc-7d83-4556-839f-dbd4d69dccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all from `sql.types`\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "801bf609-f684-4357-8a60-1e7aad91617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom function to convert the data type of DataFrame columns\n",
    "def convertColumn(df, names, newType):\n",
    "    for name in names: \n",
    "        df = df.withColumn(name, df[name].cast(newType))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dbf8eec5-7d98-43af-b076-7d73bcb06dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of continuous features\n",
    "CONTI_FEATURES  = ['age', 'fnlwgt','capital-gain', 'educational-num', 'capital-loss', 'hours-per-week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "70039206-e961-4c4e-8d46-aec235507898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the type\n",
    "df_string = convertColumn(df, CONTI_FEATURES, FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "917e82f0-f618-476b-aa8b-b94e2f5b1afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: float (nullable = true)\n",
      " |-- age-square: double (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: float (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: float (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- x: integer (nullable = true)\n",
      " |-- capital-gain: float (nullable = true)\n",
      " |-- capital-loss: float (nullable = true)\n",
      " |-- hours-per-week: float (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_string.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "3e20c9ab-394a-4bd6-9bf8-6600fe8b9997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- age-square: double (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- x: integer (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- educational-num-index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "stringIndexer = StringIndexer(inputCol=\"educational-num\", outputCol=\"educational-num-index\")\n",
    "model = stringIndexer.fit(df)\n",
    "df = model.transform(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "5d5b6fbf-8982-4b67-83cb-b6fac617f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------------+\n",
      "|educational-num|educational-num-index|\n",
      "+---------------+---------------------+\n",
      "|7              |5.0                  |\n",
      "|9              |0.0                  |\n",
      "|12             |6.0                  |\n",
      "|10             |1.0                  |\n",
      "|10             |1.0                  |\n",
      "|6              |7.0                  |\n",
      "|9              |0.0                  |\n",
      "|15             |9.0                  |\n",
      "|10             |1.0                  |\n",
      "|4              |8.0                  |\n",
      "|9              |0.0                  |\n",
      "|13             |2.0                  |\n",
      "|9              |0.0                  |\n",
      "|9              |0.0                  |\n",
      "|9              |0.0                  |\n",
      "|14             |3.0                  |\n",
      "|10             |1.0                  |\n",
      "|9              |0.0                  |\n",
      "|9              |0.0                  |\n",
      "|16             |12.0                 |\n",
      "+---------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['educational-num','educational-num-index']).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e2c4bd1b-a594-4bac-9cc8-75ed6a04b829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|   education|count|\n",
      "+------------+-----+\n",
      "|   Preschool|   83|\n",
      "|     1st-4th|  247|\n",
      "|     5th-6th|  509|\n",
      "|   Doctorate|  594|\n",
      "|        12th|  657|\n",
      "|         9th|  756|\n",
      "| Prof-school|  834|\n",
      "|     7th-8th|  955|\n",
      "|        10th| 1389|\n",
      "|  Assoc-acdm| 1601|\n",
      "|        11th| 1812|\n",
      "|   Assoc-voc| 2061|\n",
      "|     Masters| 2657|\n",
      "|   Bachelors| 8025|\n",
      "|Some-college|10878|\n",
      "|     HS-grad|15784|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.groupBy(\"education\").count().sort(\"count\",ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8f384ff6-d7bf-49f1-a4a3-edf99cedd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------------------+------------------+-----------------+------------------+--------------+------+---------------------+\n",
      "|summary|               age|        age-square|  workclass|            fnlwgt|   education|   educational-num|marital-status|      occupation|relationship|              race|                 x|      capital-gain|     capital-loss|    hours-per-week|native-country|income|educational-num-index|\n",
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------------------+------------------+-----------------+------------------+--------------+------+---------------------+\n",
      "|  count|             48842|             48842|      48842|             48842|       48842|             48842|         48842|           48842|       48842|             48842|             48842|             48842|            48842|             48842|         48842| 48842|                48842|\n",
      "|   mean| 38.64358543876172|1681.3009295278653|       null|189664.13459727284|        null|10.078088530363212|          null|            null|        null|              null|           24421.5|1079.0676262233324|87.50231358257237|40.422382375824085|          null|  null|   2.4551205929323126|\n",
      "| stddev|13.710509934443502|1187.0661823288658|       null|105604.02542315757|        null| 2.570972755592252|          null|            null|        null|              null|14099.615260708357| 7452.019057655413|403.0045521243591|12.391444024252289|          null|  null|   3.1959866507489902|\n",
      "|    min|                17|             289.0|          ?|             12285|        10th|                 1|      Divorced|               ?|     Husband|Amer-Indian-Eskimo|                 1|                 0|                0|                 1|             ?| <=50K|                  0.0|\n",
      "|    max|                90|            8100.0|Without-pay|           1490400|Some-college|                16|       Widowed|Transport-moving|        Wife|             White|             48842|             99999|             4356|                99|    Yugoslavia|  >50K|                 15.0|\n",
      "+-------+------------------+------------------+-----------+------------------+------------+------------------+--------------+----------------+------------+------------------+------------------+------------------+-----------------+------------------+--------------+------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "33dd9f7e-7929-4576-987d-fecd7c32681d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      capital-gain|\n",
      "+-------+------------------+\n",
      "|  count|             48842|\n",
      "|   mean|1079.0676262233324|\n",
      "| stddev| 7452.019057655413|\n",
      "|    min|                 0|\n",
      "|    max|             99999|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.describe('capital-gain').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "429cb4db-950b-4cb4-9c57-68a31d9716f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|income|\n",
      "+------+\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "|  >50K|\n",
      "|  >50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "|  >50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "|  >50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "|  >50K|\n",
      "|  >50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "| <=50K|\n",
      "|  >50K|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('income').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d2cdbb2d-0903-4d48-9fc4-184aed14f187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----+\n",
      "|age_income|<=50K|>50K|\n",
      "+----------+-----+----+\n",
      "|        17|  595|   0|\n",
      "|        18|  862|   0|\n",
      "|        19| 1050|   3|\n",
      "|        20| 1112|   1|\n",
      "|        21| 1090|   6|\n",
      "|        22| 1161|  17|\n",
      "|        23| 1307|  22|\n",
      "|        24| 1162|  44|\n",
      "|        25| 1119|  76|\n",
      "|        26| 1068|  85|\n",
      "|        27| 1117| 115|\n",
      "|        28| 1101| 179|\n",
      "|        29| 1025| 198|\n",
      "|        30| 1031| 247|\n",
      "|        31| 1050| 275|\n",
      "|        32|  957| 296|\n",
      "|        33| 1045| 290|\n",
      "|        34|  949| 354|\n",
      "|        35|  997| 340|\n",
      "|        36|  948| 400|\n",
      "+----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If we want to know how the age get related to the income\n",
    "df.crosstab('age','income').sort('age_income').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "45b2d0ae-c459-48cb-9c87-8cf878a1fe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'age-square',\n",
       " 'workclass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'x',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " 'income',\n",
       " 'educational-num-index']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop a column\n",
    "df.drop('educational-num').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6aa13cbe-f1e3-4896-8079-d2ac6c934a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20211"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by one column as a paremeter\n",
    "df.filter(df.age > 40).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0ceba458-2b72-45ed-871d-fbaa2a49199d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7086"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by TWO columns as a paremeter\n",
    "df.filter((df.age > 40) & (df.income == '>50K')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a75af7a4-2ae0-49e1-83e6-f76ffbaf5777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|      marital-status| avg(capital-gain)|\n",
      "+--------------------+------------------+\n",
      "|           Separated| 581.8424836601307|\n",
      "|       Never-married|  384.382639449029|\n",
      "|Married-spouse-ab...| 629.0047770700637|\n",
      "|            Divorced| 793.6755615860094|\n",
      "|             Widowed| 603.6442687747035|\n",
      "|   Married-AF-spouse|2971.6216216216217|\n",
      "|  Married-civ-spouse|1739.7006121810625|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate data by group\n",
    "df.groupby('marital-status').agg({'capital-gain': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1de31b93-f3ab-48b7-b5f0-167bfadbeb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|      marital-status|count(1)|\n",
      "+--------------------+--------+\n",
      "|           Separated|    1530|\n",
      "|       Never-married|   16117|\n",
      "|Married-spouse-ab...|     628|\n",
      "|            Divorced|    6633|\n",
      "|             Widowed|    1518|\n",
      "|   Married-AF-spouse|      37|\n",
      "|  Married-civ-spouse|   22379|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('marital-status').agg({'*': 'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8ceb2c86-b9a2-4728-b494-9a15c6f87e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|      marital-status|min(age)|\n",
      "+--------------------+--------+\n",
      "|           Separated|      18|\n",
      "|       Never-married|      17|\n",
      "|Married-spouse-ab...|      17|\n",
      "|            Divorced|      18|\n",
      "|             Widowed|      17|\n",
      "|   Married-AF-spouse|      19|\n",
      "|  Married-civ-spouse|      17|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.groupby('marital-status').agg(F.min(df.age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c62ce79e-cf5d-4577-b622-e8a3e1a707da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+\n",
      "|marital-status|age|\n",
      "+--------------+---+\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "| Never-married| 17|\n",
      "+--------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('marital-status','age').filter((df['marital-status'] == 'Never-married') & (df.age < 18) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "35f90566-2548-4101-aec4-2f123a50aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation and add it to the DataFrame\n",
    "df = df.withColumn(\"age-square\", F.col(\"age\") ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cb12a17c-5fb7-4df7-a4f8-17cd39d3dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- age-square: double (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: integer (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- educational-num: integer (nullable = true)\n",
      " |-- marital-status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- x: integer (nullable = true)\n",
      " |-- capital-gain: integer (nullable = true)\n",
      " |-- capital-loss: integer (nullable = true)\n",
      " |-- hours-per-week: integer (nullable = true)\n",
      " |-- native-country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      " |-- educational-num-index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f9734c52-904e-4dbc-9db8-a200e715dd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=25, age-square=625.0, workclass='Private', fnlwgt=226802, education='11th', educational-num=7, marital-status='Never-married', occupation='Machine-op-inspct', relationship='Own-child', race='Black', x=1, capital-gain=0, capital-loss=0, hours-per-week=40, native-country='United-States', income='<=50K')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the order of the displayed columns\n",
    "COLUMNS = ['age', 'age-square', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status',\n",
    "           'occupation', 'relationship', 'race', 'x', 'capital-gain', 'capital-loss',\n",
    "           'hours-per-week', 'native-country', 'income']\n",
    "df = df.select(COLUMNS)\n",
    "df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "42178e9d-19a4-417c-85b7-46da4955f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the netherlands \n",
    "df_remove = df.filter(df['native-country'] != 'Holand-Netherlands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ea9274ca-77a6-4323-8b61-5b5557409d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('age-square', 'double'),\n",
       " ('workclass', 'string'),\n",
       " ('fnlwgt', 'int'),\n",
       " ('education', 'string'),\n",
       " ('educational-num', 'int'),\n",
       " ('marital-status', 'string'),\n",
       " ('occupation', 'string'),\n",
       " ('relationship', 'string'),\n",
       " ('race', 'string'),\n",
       " ('x', 'int'),\n",
       " ('capital-gain', 'int'),\n",
       " ('capital-loss', 'int'),\n",
       " ('hours-per-week', 'int'),\n",
       " ('native-country', 'string'),\n",
       " ('income', 'string')]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4ca08324-960b-4670-999a-3f3239a5bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test2.csv\n",
    "df_pyspark=spark.read.csv('test2.csv',header=True,inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c8701c08-fdbb-42c7-9412-1cdf19235358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   Karl|  31|        10| 30000|\n",
      "| Sussie|  30|         8| 25000|\n",
      "|  Sunny|  29|         4| 20000|\n",
      "|   Paul|  24|         3| 20000|\n",
      "|  Henry|  21|         1| 15000|\n",
      "|Shutter|  23|         2| 18000|\n",
      "|  Manny|null|      null| 40000|\n",
      "|   null|  34|        10| 38000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "ff117e79-6137-4b90-88ed-7f27404b6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Karl| 31|        10| 30000|\n",
      "| Sussie| 30|         8| 25000|\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "|  Henry| 21|         1| 15000|\n",
      "|Shutter| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop all the rows that contains a null value\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f7af46ee-603f-42f9-8f5b-9060ff47bab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Karl| 31|        10| 30000|\n",
      "| Sussie| 30|         8| 25000|\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "|  Henry| 21|         1| 15000|\n",
      "|Shutter| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The same but for ANY value\n",
    "df_pyspark.na.drop(how=\"any\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "62bca121-5316-4553-8359-bfa7bfcb93a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Karl| 31|        10| 30000|\n",
      "| Sussie| 30|         8| 25000|\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "|  Henry| 21|         1| 15000|\n",
      "|Shutter| 23|         2| 18000|\n",
      "|   null| 34|        10| 38000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Threshold: Preserve if the row has 3 or more attributes with a NOT_NULL VALUE\n",
    "df_pyspark.na.drop(how=\"any\",thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "624c6b71-75a6-4428-bdbe-5f0cad7c755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Karl| 31|        10| 30000|\n",
      "| Sussie| 30|         8| 25000|\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "|  Henry| 21|         1| 15000|\n",
      "|Shutter| 23|         2| 18000|\n",
      "|   null| 34|        10| 38000|\n",
      "|   null| 36|      null|  null|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply only to the column age\n",
    "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "6953eeca-1ff1-48c8-be17-b056e0449047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Karl| 31|        10| 30000|\n",
      "| Sussie| 30|         8| 25000|\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "|  Henry| 21|         1| 15000|\n",
      "|Shutter| 23|         2| 18000|\n",
      "|  Manny|  0|         0| 40000|\n",
      "|   null| 34|        10| 38000|\n",
      "|   null| 36|         0|  null|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filling the Missing Value\n",
    "df_pyspark.na.fill(0,['Experience','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fee8f313-aeac-45b8-b9f6-818ed4bc9715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Karl|  31|        10| 30000|         31|                10|         30000|\n",
      "| Sussie|  30|         8| 25000|         30|                 8|         25000|\n",
      "|  Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
      "|   Paul|  24|         3| 20000|         24|                 3|         20000|\n",
      "|  Henry|  21|         1| 15000|         21|                 1|         15000|\n",
      "|Shutter|  23|         2| 18000|         23|                 2|         18000|\n",
      "|  Manny|null|      null| 40000|         29|                 4|         40000|\n",
      "|   null|  34|        10| 38000|         34|                10|         38000|\n",
      "|   null|  36|      null|  null|         36|                 4|         20000|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Define imputer columns and output columns\n",
    "imputer = Imputer(\n",
    "    inputCols = ['age', 'Experience', 'Salary'], \n",
    "    outputCols = [\n",
    "        \"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']\n",
    "    ]).setStrategy(\"median\")\n",
    "\n",
    "# Add imputation cols to df\n",
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2fec53c-c133-4ccd-9197-2e202246cf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read The dataset\n",
    "training = spark.read.csv('test1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a8a085d7-c22c-4911-a467-7597e04bb322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Karl| 31|        10| 30000|\n",
      "| Sussie| 30|         8| 25000|\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "|  Henry| 21|         1| 15000|\n",
      "|Shutter| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "972d5e80-3bc8-49eb-a160-5e4fd2cd1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Age,Experience]--> new feature --> independent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ddb9c5-6148-4487-a8b9-d4e3c36a6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Make the vector of the new feature\n",
    "featureassembler = VectorAssembler(\n",
    "    inputCols = [\"age\",\"Experience\"],\n",
    "    outputCol = \"Independent Features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df7782a6-49a4-4a6c-b3ca-3f29837f8466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+--------------------+\n",
      "|   Name|age|Experience|Salary|Independent Features|\n",
      "+-------+---+----------+------+--------------------+\n",
      "|   Karl| 31|        10| 30000|         [31.0,10.0]|\n",
      "| Sussie| 30|         8| 25000|          [30.0,8.0]|\n",
      "|  Sunny| 29|         4| 20000|          [29.0,4.0]|\n",
      "|   Paul| 24|         3| 20000|          [24.0,3.0]|\n",
      "|  Henry| 21|         1| 15000|          [21.0,1.0]|\n",
      "|Shutter| 23|         2| 18000|          [23.0,2.0]|\n",
      "+-------+---+----------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform yout current dataframe adding the new feature\n",
    "output = featureassembler.transform(training)\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "954b93e8-ecec-41c0-ab04-61f09beefe67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|         [31.0,10.0]| 30000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|          [29.0,4.0]| 20000|\n",
      "|          [24.0,3.0]| 20000|\n",
      "|          [21.0,1.0]| 15000|\n",
      "|          [23.0,2.0]| 18000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select the new feature and the independent feature that we need to predict\n",
    "finalized_data = output.select(\"Independent Features\",\"Salary\")\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c614b36-5c2a-4096-afff-7688a3e43270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|Independent Features|Salary|\n",
      "+--------------------+------+\n",
      "|          [23.0,2.0]| 18000|\n",
      "|          [30.0,8.0]| 25000|\n",
      "|         [31.0,10.0]| 30000|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Divide our data in data to train the model and data to predict\n",
    "train_data,test_data = finalized_data.randomSplit([0.75,0.25])\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d41c0d2b-3b22-4a8b-97f2-e5e8f60776ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new regressor in order to input the features and the dependant feature\n",
    "regressor = LinearRegression(\n",
    "    featuresCol = 'Independent Features', \n",
    "    labelCol = 'Salary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04892075-bc1e-426f-847a-4afb30bf6bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "regressor = regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a1a9c16-702e-45e2-ad83-0d7dc62c2750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-714.2857, 3571.4286])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd960e5-6a45-4655-9c39-88c01ad5bd9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26428.57142857082"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intercepts\n",
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77d4e781-7f89-43f1-97f0-79f27c0b6a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred_results = regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50ba9dd8-e3cc-49a6-8194-b34c5eb2ee55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----------------+\n",
      "|Independent Features|Salary|       prediction|\n",
      "+--------------------+------+-----------------+\n",
      "|          [23.0,2.0]| 18000|17142.85714285713|\n",
      "|          [30.0,8.0]| 25000| 33571.4285714283|\n",
      "|         [31.0,10.0]| 30000|39999.99999999959|\n",
      "+--------------------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09171ca3-277b-42bc-b1d8-94179bced9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6476.190476190255, 58068027.21088012)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
